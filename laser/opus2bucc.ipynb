{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname = \"Tatoeba\"\n",
    "l1 = \"ja\"\n",
    "l2 = \"en\"\n",
    "lang= l1 + \"-\" + l2\n",
    "opus_lang = \"-\".join(sorted([l1, l2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opus_l1_path = \"./{:s}.{:s}.{:s}\".format(dataname, opus_lang, l1)\n",
    "opus_l2_path = \"./{:s}.{:s}.{:s}\".format(dataname, opus_lang, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "opus_l2 = [l.strip() for l in open(opus_l2_path).readlines()]\n",
    "opus_l1 = [l.strip() for l in open(opus_l1_path).readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202167, 177964)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(202167, 177964)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opus_l2_dedup = []\n",
    "opus_l1_dedup = []\n",
    "prev_l2 = None\n",
    "prev_l1 = None\n",
    "\n",
    "opus_gen = zip(opus_l2, opus_l1)\n",
    "prev_l2, prev_l1 = next(opus_gen)\n",
    "for en, ja in opus_gen:        \n",
    "    if prev_l2 != en and prev_l1 != ja:\n",
    "        opus_l2_dedup.append(en)\n",
    "        opus_l1_dedup.append(ja)\n",
    "\n",
    "    prev_l2 = en\n",
    "    prev_l1 = ja\n",
    "\n",
    "len(opus_l2), len(opus_l2_dedup)\n",
    "len(opus_l1), len(opus_l1_dedup)\n",
    "\n",
    "opus_l2 = opus_l2_dedup\n",
    "opus_l1 = opus_l1_dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "opus_size = len(opus_l2)\n",
    "train_size = opus_size//2\n",
    "test_size = opus_size - train_size\n",
    "\n",
    "np.random.seed(123)\n",
    "opus_inds = np.random.permutation(np.arange(opus_size))\n",
    "\n",
    "train_gold_size = int(train_size * 0.2)\n",
    "test_gold_size = int(test_size * 0.2)\n",
    "\n",
    "train_inds = opus_inds[:train_size]\n",
    "test_inds = opus_inds[train_size:]\n",
    "\n",
    "train_gold_inds = train_inds[:train_gold_size]\n",
    "train_mono_inds = train_inds[train_gold_size:]\n",
    "train_mono_size = len(train_mono_inds)//2\n",
    "train_mono_l2_inds = train_mono_inds[:train_mono_size]\n",
    "train_mono_l1_inds = train_mono_inds[train_mono_size:]\n",
    "\n",
    "test_gold_inds = test_inds[:test_gold_size]\n",
    "test_mono_inds = test_inds[test_gold_size:]\n",
    "test_mono_size = len(test_mono_inds)//2\n",
    "test_mono_l2_inds = test_mono_inds[:test_mono_size]\n",
    "test_mono_l1_inds = test_mono_inds[test_mono_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89d040559c04ccbb4059eb7150a20b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=177964), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_mono_l2 = []\n",
    "train_mono_l1 = []\n",
    "train_gold = []\n",
    "train_gold_ladder = []\n",
    "test_mono_l2= []\n",
    "test_mono_l1 = []\n",
    "test_gold = []\n",
    "test_gold_ladder = []\n",
    "i = 0\n",
    "for en, ja in tqdm([(enja[0], enja[1]) for enja in zip(opus_l2, opus_l1)]):\n",
    "    train_l2_size = len(train_mono_l2) + 1\n",
    "    train_l1_size = len(train_mono_l1) + 1\n",
    "    test_l2_size = len(test_mono_l2) + 1\n",
    "    test_l1_size = len(test_mono_l1) + 1\n",
    "    if i in train_gold_inds:\n",
    "        train_mono_l2.append(\"{:s}-{:08d}\\t{:s}\".format(l2, train_l2_size, opus_l2[i]))\n",
    "        train_mono_l1.append(\"{:s}-{:08d}\\t{:s}\".format(l1, train_l1_size, opus_l1[i]))\n",
    "        train_gold.append(\"{:s}-{:08d}\\t{:s}-{:08d}\".format(l1, train_l1_size, l2, train_l2_size))\n",
    "        train_gold_ladder.append(\"{:d}\\t{:d}\".format(train_l2_size-1, train_l1_size-1))\n",
    "    elif i in train_mono_l2_inds:\n",
    "        train_mono_l2.append(\"{:s}-{:08d}\\t{:s}\".format(l2, train_l2_size, opus_l2[i]))\n",
    "    elif i in train_mono_l1_inds:\n",
    "        train_mono_l1.append(\"{:s}-{:08d}\\t{:s}\".format(l1, train_l1_size, opus_l1[i]))\n",
    "    elif i in test_gold_inds:\n",
    "        test_mono_l2.append(\"{:s}-{:08d}\\t{:s}\".format(l2, test_l2_size, opus_l2[i]))\n",
    "        test_mono_l1.append(\"{:s}-{:08d}\\t{:s}\".format(l1, test_l1_size, opus_l1[i]))\n",
    "        test_gold.append(\"{:s}-{:08d}\\t{:s}-{:08d}\".format(l1, test_l1_size, l2, test_l2_size))\n",
    "        test_gold_ladder.append(\"{:d}\\t{:d}\".format(test_l2_size-1, test_l1_size-1))\n",
    "    elif i in test_mono_l2_inds:\n",
    "        test_mono_l2.append(\"{:s}-{:08d}\\t{:s}\".format(l2, test_l2_size, opus_l2[i]))\n",
    "    elif i in test_mono_l1_inds:\n",
    "        test_mono_l1.append(\"{:s}-{:08d}\\t{:s}\".format(l1, test_l1_size, opus_l1[i]))\n",
    "    else:\n",
    "        raise ValueError(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "lang_dir = Path(lang)\n",
    "if not lang_dir.exists():\n",
    "    lang_dir.mkdir()\n",
    "\n",
    "with open(\"./{:s}/{:s}.training.{:s}\".format(lang, lang, l1), \"w\") as f:\n",
    "    for e in train_mono_l1:\n",
    "        print(e, file=f)\n",
    "with open(\"./{:s}/{:s}.training.{:s}\".format(lang, lang, l2), \"w\") as f:\n",
    "    for e in train_mono_l2:\n",
    "        print(e, file=f)\n",
    "with open(\"./{:s}/{:s}.training.gold\".format(lang, lang), \"w\") as f:\n",
    "    for e in train_gold:\n",
    "        print(e, file=f)\n",
    "with open(\"./{:s}/{:s}.test.{:s}\".format(lang, lang, l1), \"w\") as f:\n",
    "    for e in test_mono_l1:\n",
    "        print(e, file=f)\n",
    "with open(\"./{:s}/{:s}.test.{:s}\".format(lang, lang, l2), \"w\") as f:\n",
    "    for e in test_mono_l2:\n",
    "        print(e, file=f)\n",
    "with open(\"./{:s}/{:s}.test.gold\".format(lang, lang), \"w\") as f:\n",
    "    for e in test_gold:\n",
    "        print(e, file=f)\n",
    "\n",
    "# for hunalign (l2-l1)\n",
    "with open(\"./{:s}/{:s}-{:s}.training.hunalign.ladder\".format(lang, l2, l1), \"w\") as f:\n",
    "    for e in train_gold_ladder:\n",
    "        print(e, file=f)\n",
    "with open(\"./{:s}/{:s}-{:s}.test.hunalign.ladder\".format(lang, l2, l1), \"w\") as f:\n",
    "    for e in test_gold_ladder:\n",
    "        print(e, file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
